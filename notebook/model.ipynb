{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e8d20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ed3fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "z_dim = 64\n",
    "loss = nn.BCELoss()\n",
    "sample_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1251098",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,z_dim):\n",
    "        super().__init__()\n",
    "        self.first = nn.Linear(z_dim,128*7*7)\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128,64,4,2,1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64,1,4,2,1),\n",
    "            nn.Tanh()\n",
    "\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x=self.first(x)\n",
    "        x = x.view(-1,128,7,7)\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b5c09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Conv2d(1,64,4,2,1),\n",
    "            nn.LeakyReLU(.2),\n",
    "            nn.Conv2d(64,128,4,2,1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*7*7,1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.disc(x)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5ce4d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,),(0.5,))\n",
    "    ]\n",
    ")\n",
    "dataset = datasets.FashionMNIST(root=\"dataset/\",transform=transforms,download=True)\n",
    "loader = DataLoader(dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed59a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator()\n",
    "gen = Generator(z_dim)\n",
    "disc_optim = optim.Adam(disc.parameters(),lr=lr)\n",
    "gen_optim = optim.Adam(gen.parameters(),lr=lr)\n",
    "fixed_noise = torch.randn((batch_size,z_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b1d00ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_idx , (real,_) in enumerate(loader):\n",
    "        real = real.view(-1,1,28,28)\n",
    "        noise = torch.randn(batch_size,z_dim)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real).view(-1)\n",
    "        disc_fake = disc(fake.detach()).view(-1)\n",
    "        disc_loss_real = loss(disc_real,torch.ones_like(disc_real))\n",
    "        disc_loss_fake = loss(disc_fake,torch.zeros_like(disc_fake))\n",
    "        loss_D = (disc_loss_real+disc_loss_fake)/2\n",
    "        disc.zero_grad()\n",
    "        loss_D.backward()\n",
    "        disc_optim.step()\n",
    "\n",
    "        output = disc(fake).view(-1)\n",
    "        loss_G = loss(output,torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        loss_G.backward()\n",
    "        gen_optim.step()\n",
    "        \n",
    "        if epoch%sample_size==0:\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise).view(-1,1,28,28)\n",
    "                grid = torchvision.utils.make_grid(fake,normalize=True)\n",
    "                plt.imshow(grid.permute(1,2,0))\n",
    "                plt.axis(\"off\")\n",
    "                torchvision.utils.save_image(\n",
    "                    grid,\n",
    "                    f\"samplesDCGAN/grid_epoch_{epoch}.png\"\n",
    "                )\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d738697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed168f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c962f775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
